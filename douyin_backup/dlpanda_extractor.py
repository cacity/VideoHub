#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
DLPanda.com æŠ–éŸ³è§†é¢‘æå–å™¨
ä½¿ç”¨ dlpanda.com ä½œä¸ºç¬¬ä¸‰æ–¹æœåŠ¡ä¸‹è½½æŠ–éŸ³è§†é¢‘
"""

import requests
import re
import time
import json
from typing import Optional, Dict, Any, Callable
from urllib.parse import urljoin, urlparse

class DLPandaExtractor:
    """åŸºäºDLPanda.comçš„æŠ–éŸ³è§†é¢‘æå–å™¨"""
    
    def __init__(self):
        self.base_url = "https://dlpanda.com"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'DNT': '1',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        })
    
    def extract_video_info(self, url: str, progress_callback: Optional[Callable] = None) -> Optional[Dict[str, Any]]:
        """
        ä»DLPandaæå–æŠ–éŸ³è§†é¢‘ä¿¡æ¯
        :param url: æŠ–éŸ³è§†é¢‘é“¾æ¥
        :param progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
        :return: è§†é¢‘ä¿¡æ¯å­—å…¸
        """
        try:
            print(f"ğŸ¼ ä½¿ç”¨DLPandaæå–è§†é¢‘ä¿¡æ¯: {url}")
            if progress_callback:
                progress_callback(10, "è¿æ¥DLPandaæœåŠ¡...")
            
            # æ­¥éª¤1: è·å–ä¸»é¡µé¢å’Œtoken
            if progress_callback:
                progress_callback(20, "è·å–è®¿é—®ä»¤ç‰Œ...")
            
            token = self._get_token()
            if not token:
                print("âŒ æ— æ³•è·å–è®¿é—®ä»¤ç‰Œ")
                return None
            
            # æ­¥éª¤2: æäº¤è§†é¢‘URL
            if progress_callback:
                progress_callback(40, "æäº¤è§†é¢‘é“¾æ¥...")
            
            video_data = self._submit_url(url, token)
            if not video_data:
                print("âŒ æäº¤URLå¤±è´¥")
                return None
            
            if progress_callback:
                progress_callback(80, "è§£æè§†é¢‘ä¿¡æ¯...")
            
            # æ­¥éª¤3: è§£æè¿”å›çš„è§†é¢‘ä¿¡æ¯
            video_info = self._parse_video_data(video_data, url)
            
            if progress_callback:
                progress_callback(100, "æå–å®Œæˆ")
            
            # æ ‡è®°ä¸ºDLPandaæå–
            video_info['extraction_method'] = 'dlpanda'
            video_info['from_dlpanda'] = True
            
            return video_info
            
        except Exception as e:
            print(f"âŒ DLPandaæå–å¤±è´¥: {e}")
            return None
    
    def _get_token(self) -> Optional[str]:
        """è·å–é¡µé¢token"""
        try:
            print("ğŸ” æ­£åœ¨è·å–DLPandaé¡µé¢...")
            response = self.session.get(self.base_url, timeout=10)
            response.raise_for_status()
            
            print(f"ğŸ“„ é¡µé¢å“åº”çŠ¶æ€: {response.status_code}")
            print(f"ğŸ“„ é¡µé¢é•¿åº¦: {len(response.text)}")
            
            # å¤šç§tokenæå–æ¨¡å¼
            token_patterns = [
                r'name="t0ken"[^>]*value="([^"]*)"',
                r'id="token"[^>]*value="([^"]*)"',
                r'<input[^>]*name="t0ken"[^>]*value="([^"]*)"',
                r'<input[^>]*value="([^"]*)"[^>]*name="t0ken"',
                r't0ken["\']?\s*:\s*["\']([^"\']*)["\']',
                r'token["\']?\s*:\s*["\']([^"\']*)["\']'
            ]
            
            for i, pattern in enumerate(token_patterns):
                token_match = re.search(pattern, response.text, re.IGNORECASE)
                if token_match:
                    token = token_match.group(1).strip()
                    if token and len(token) > 3:  # ç¡®ä¿tokenä¸ä¸ºç©ºä¸”æœ‰æ„ä¹‰
                        print(f"âœ… è·å–åˆ°token (æ¨¡å¼{i+1}): {token}")
                        return token
            
            # å¦‚æœéƒ½æ²¡æ‰¾åˆ°ï¼Œæ‰“å°éƒ¨åˆ†é¡µé¢å†…å®¹è¿›è¡Œè°ƒè¯•
            print("âŒ æœªæ‰¾åˆ°tokenï¼Œé¡µé¢å†…å®¹ç‰‡æ®µ:")
            lines = response.text.split('\n')
            for line_num, line in enumerate(lines):
                if 'token' in line.lower() or 't0ken' in line.lower():
                    print(f"è¡Œ {line_num}: {line.strip()[:200]}")
            
            print("ğŸ” å°è¯•ä½¿ç”¨é»˜è®¤token...")
            # å¦‚æœå®åœ¨æ‰¾ä¸åˆ°ï¼Œå°è¯•ä½¿ç”¨è§‚å¯Ÿåˆ°çš„å›ºå®štoken
            default_token = "b8b6c49aToTA"
            print(f"âš ï¸ ä½¿ç”¨é»˜è®¤token: {default_token}")
            return default_token
                
        except Exception as e:
            print(f"âŒ è·å–tokenå¤±è´¥: {e}")
            # fallbackåˆ°é»˜è®¤token
            default_token = "b8b6c49aToTA"
            print(f"âš ï¸ å¼‚å¸¸æƒ…å†µä¸‹ä½¿ç”¨é»˜è®¤token: {default_token}")
            return default_token
    
    def _submit_url(self, url: str, token: str) -> Optional[Dict]:
        """æäº¤URLåˆ°DLPanda"""
        try:
            print(f"ğŸ“¤ æäº¤URLåˆ°DLPanda: {url}")
            print(f"ğŸ”‘ ä½¿ç”¨token: {token}")
            
            # å‡†å¤‡POSTæ•°æ®
            data = {
                'url': url,
                't0ken': token
            }
            
            # æ·»åŠ æ›´å¤šheadersæ¨¡æ‹ŸçœŸå®æµè§ˆå™¨
            headers = {
                'Content-Type': 'application/x-www-form-urlencoded',
                'Origin': self.base_url,
                'Referer': self.base_url,
                'X-Requested-With': 'XMLHttpRequest'
            }
            
            print("ğŸ“¤ å‘é€GETè¯·æ±‚ï¼ˆè¡¨å•ä½¿ç”¨GETæ–¹æ³•ï¼‰...")
            # DLPandaä½¿ç”¨GETæ–¹æ³•æäº¤è¡¨å•
            response = self.session.get(
                self.base_url,
                params=data,  # ä½¿ç”¨paramsè€Œä¸æ˜¯data
                timeout=30,
                allow_redirects=True
            )
            
            print(f"ğŸ“„ å“åº”çŠ¶æ€: {response.status_code}")
            print(f"ğŸ“„ æœ€ç»ˆURL: {response.url}")
            print(f"ğŸ“„ å“åº”é•¿åº¦: {len(response.text)}")
            
            if response.status_code != 200:
                print(f"âŒ è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                print(f"å“åº”å†…å®¹å‰500å­—ç¬¦: {response.text[:500]}")
                return None
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ä¸‹è½½é“¾æ¥
            print("ğŸ” æŸ¥æ‰¾ä¸‹è½½é“¾æ¥...")
            download_links = self._extract_download_links(response.text)
            if download_links:
                print(f"âœ… æ‰¾åˆ° {len(download_links)} ä¸ªä¸‹è½½é“¾æ¥")
                return {
                    'html': response.text,
                    'download_links': download_links,
                    'url': response.url
                }
            else:
                print("âš ï¸ æœªæ‰¾åˆ°ç›´æ¥ä¸‹è½½é“¾æ¥ï¼Œå°è¯•æ£€æŸ¥æ˜¯å¦æœ‰å¼‚æ­¥åŠ è½½...")
            
            # æ£€æŸ¥é¡µé¢æ˜¯å¦åŒ…å«è§†é¢‘ä¿¡æ¯ï¼Œå¯èƒ½éœ€è¦ç­‰å¾…JavaScriptæ‰§è¡Œ
            print("ğŸ” æ£€æŸ¥é¡µé¢æ˜¯å¦æœ‰å¤„ç†ç»“æœ...")
            
            # ä¸å†é‡è¯•HTTPè¯·æ±‚ï¼Œè€Œæ˜¯æ£€æŸ¥å½“å‰é¡µé¢æ˜¯å¦æœ‰æœ‰ç”¨ä¿¡æ¯
            # æ£€æŸ¥æ˜¯å¦é¡µé¢æœ‰é‡å®šå‘æˆ–å…¶ä»–æœ‰ç”¨ä¿¡æ¯
            if 'download' in response.text.lower() or 'video' in response.text.lower():
                print("ğŸ’¡ é¡µé¢åŒ…å«è§†é¢‘ç›¸å…³å†…å®¹ï¼Œå¯èƒ½éœ€è¦JavaScriptå¤„ç†")
                # è¿™é‡Œå¯ä»¥ä½œä¸ºSeleniumçš„è§¦å‘æ¡ä»¶
            
            # å°è¯•æŸ¥æ‰¾å¯èƒ½çš„APIç«¯ç‚¹
            ajax_data = self._check_for_ajax_response(response.text, url, token)
            if ajax_data:
                return ajax_data
            
            # å¦‚æœè¿˜æ˜¯æ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•ä½¿ç”¨seleniumæ–¹æ³•
            print("ğŸ”„ å°è¯•ä½¿ç”¨Seleniumæ¨¡å¼...")
            selenium_result = self._try_selenium_method(url)
            if selenium_result:
                return selenium_result
            
            # å³ä½¿æ²¡æœ‰ä¸‹è½½é“¾æ¥ï¼Œä¹Ÿè¿”å›é¡µé¢å†…å®¹ä¾›è¿›ä¸€æ­¥åˆ†æ
            print("âš ï¸ è¿”å›é¡µé¢å†…å®¹ä¾›åˆ†æ...")
            return {
                'html': response.text,
                'download_links': [],
                'url': response.url
            }
            
        except Exception as e:
            print(f"âŒ æäº¤URLå¤±è´¥: {e}")
            import traceback
            print(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return None
    
    def _check_for_ajax_response(self, html: str, original_url: str, token: str) -> Optional[Dict]:
        """æ£€æŸ¥æ˜¯å¦æœ‰AJAXå“åº”"""
        try:
            # æŸ¥æ‰¾å¯èƒ½çš„AJAXç«¯ç‚¹
            ajax_patterns = [
                r'\.post\(["\']([^"\']*)["\']',
                r'url:\s*["\']([^"\']*)["\']',
                r'action=["\']([^"\']*)["\']'
            ]
            
            for pattern in ajax_patterns:
                matches = re.findall(pattern, html)
                for match in matches:
                    if 'download' in match.lower() or 'api' in match.lower():
                        ajax_url = urljoin(self.base_url, match)
                        print(f"ğŸ” å°è¯•AJAXç«¯ç‚¹: {ajax_url}")
                        
                        # å°è¯•POSTåˆ°è¿™ä¸ªç«¯ç‚¹
                        try:
                            ajax_response = self.session.post(
                                ajax_url,
                                data={'url': original_url, 't0ken': token},
                                timeout=15
                            )
                            if ajax_response.status_code == 200:
                                download_links = self._extract_download_links(ajax_response.text)
                                if download_links:
                                    return {
                                        'html': ajax_response.text,
                                        'download_links': download_links,
                                        'url': ajax_response.url
                                    }
                        except:
                            continue
            
            return None
            
        except Exception as e:
            print(f"âš ï¸ æ£€æŸ¥AJAXå“åº”å¤±è´¥: {e}")
            return None
    
    def _extract_download_links(self, html: str) -> list:
        """ä»HTMLä¸­æå–ä¸‹è½½é“¾æ¥"""
        download_links = []
        
        # ä¸‹è½½é“¾æ¥çš„å„ç§æ¨¡å¼
        patterns = [
            # ç›´æ¥çš„è§†é¢‘é“¾æ¥
            r'href="([^"]*\.mp4[^"]*)"',
            r'href="([^"]*video[^"]*)"',
            r'href="([^"]*download[^"]*)"',
            # æŒ‰é’®å’Œé“¾æ¥
            r'<a[^>]*class="[^"]*download[^"]*"[^>]*href="([^"]*)"',
            r'<a[^>]*href="([^"]*)"[^>]*download',
            r'<button[^>]*data-url="([^"]*)"',
            r'<button[^>]*onclick="[^"]*\'([^\']*\.mp4[^\']*)\'"',
            # JSONæ ¼å¼
            r'"download_url":\s*"([^"]*)"',
            r'"video_url":\s*"([^"]*)"',
            r'"url":\s*"([^"]*\.mp4[^"]*)"',
            # Blob URLå’ŒJavaScriptå˜é‡
            r'blob:([^"\'>\s]*)',
            r'createObjectURL\([^)]*\)',
            r'videoUrl\s*=\s*["\']([^"\']*)["\']',
            r'downloadUrl\s*=\s*["\']([^"\']*)["\']',
            # APIå“åº”æ ¼å¼
            r'"playAddr":\s*"([^"]*)"',
            r'"src":\s*"([^"]*\.mp4[^"]*)"',
            # å¯èƒ½çš„é‡å®šå‘é“¾æ¥
            r'location\.href\s*=\s*["\']([^"\']*)["\']',
            r'window\.open\(["\']([^"\']*)["\']',
            # TikTokç‰¹æ®Šæ ¼å¼
            r'https://[^"\'>\s]*tiktok[^"\'>\s]*\.mp4[^"\'>\s]*',
            r'https://[^"\'>\s]*douyin[^"\'>\s]*\.mp4[^"\'>\s]*',
            r'https://[^"\'>\s]*aweme[^"\'>\s]*\.mp4[^"\'>\s]*',
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, html, re.IGNORECASE)
            for match in matches:
                if match and (match.startswith('http') or match.startswith('//')):
                    # å¤„ç†ç›¸å¯¹URL
                    if match.startswith('//'):
                        match = 'https:' + match
                    elif match.startswith('/'):
                        match = urljoin(self.base_url, match)
                    
                    if match not in download_links:
                        download_links.append(match)
                        print(f"ğŸ”— å‘ç°ä¸‹è½½é“¾æ¥: {match[:80]}...")
        
        return download_links
    
    def _parse_video_data(self, video_data: Dict, original_url: str) -> Dict[str, Any]:
        """è§£æè§†é¢‘æ•°æ®"""
        html = video_data.get('html', '')
        download_links = video_data.get('download_links', [])
        
        # æå–è§†é¢‘ID
        video_id_match = re.search(r'/video/(\d+)', original_url)
        video_id = video_id_match.group(1) if video_id_match else "unknown"
        
        # åŸºæœ¬è§†é¢‘ä¿¡æ¯ç»“æ„
        video_info = {
            'aweme_id': video_id,
            'desc': 'æœªçŸ¥æ ‡é¢˜',
            'duration': 0,
            'create_time': int(time.time()),
            'author': {
                'uid': '',
                'nickname': 'æœªçŸ¥ç”¨æˆ·',
                'unique_id': '',
                'avatar_url': '',
            },
            'video': {
                'play_url': '',
                'play_url_no_watermark': '',
                'cover_url': '',
                'width': 0,
                'height': 0,
                'duration': 0,
            },
            'statistics': {
                'digg_count': 0,
                'comment_count': 0,
                'share_count': 0,
                'play_count': 0,
            },
            'music': {
                'id': '',
                'title': '',
                'author': '',
                'play_url': '',
            }
        }
        
        # è®¾ç½®ä¸‹è½½é“¾æ¥
        if download_links:
            # ä¼˜å…ˆä½¿ç”¨ç¬¬ä¸€ä¸ªé“¾æ¥ä½œä¸ºä¸»è¦ä¸‹è½½é“¾æ¥
            video_info['video']['play_url'] = download_links[0]
            video_info['video']['play_url_no_watermark'] = download_links[0]
            
            # å¦‚æœæœ‰å¤šä¸ªé“¾æ¥ï¼Œå¯ä»¥å­˜å‚¨å¤‡ç”¨é“¾æ¥
            if len(download_links) > 1:
                video_info['video']['alternative_urls'] = download_links[1:]
            
            print(f"âœ… DLPandaæˆåŠŸè·å–åˆ°ä¸‹è½½é“¾æ¥")
        else:
            # å¦‚æœæ²¡æœ‰ç›´æ¥ä¸‹è½½é“¾æ¥ï¼Œæ ‡è®°ä¸ºéœ€è¦å…¶ä»–æ–¹æ³•å¤„ç†
            print("âš ï¸ DLPandaæœªè·å–åˆ°ç›´æ¥ä¸‹è½½é“¾æ¥ï¼Œæ ‡è®°ä¸ºä¿¡æ¯ä¸å®Œæ•´")
            video_info['video']['play_url'] = ''  # ç©ºå­—ç¬¦ä¸²è¡¨ç¤ºéœ€è¦å…¶ä»–æ–¹æ³•
            video_info['video']['page_url'] = video_data.get('url', original_url)
            video_info['_dlpanda_incomplete'] = True  # æ ‡è®°ä¸ºä¸å®Œæ•´
        
        # å°è¯•ä»HTMLä¸­æå–æ ‡é¢˜å’Œå…¶ä»–ä¿¡æ¯
        self._extract_metadata_from_html(html, video_info)
        
        return video_info
    
    def _extract_metadata_from_html(self, html: str, video_info: Dict):
        """ä»HTMLä¸­æå–å…ƒæ•°æ®"""
        try:
            # æå–æ ‡é¢˜
            title_patterns = [
                r'<title>([^<]+)</title>',
                r'<h1[^>]*>([^<]+)</h1>',
                r'<h2[^>]*>([^<]+)</h2>',
                r'"title":"([^"]*)"',
                r'video-title[^>]*>([^<]+)<',
            ]
            
            for pattern in title_patterns:
                match = re.search(pattern, html, re.IGNORECASE)
                if match:
                    title = match.group(1).strip()
                    if title and 'dlpanda' not in title.lower() and len(title) > 5:
                        video_info['desc'] = title
                        print(f"ğŸ“ æå–åˆ°æ ‡é¢˜: {title}")
                        break
            
            # æå–å°é¢å›¾ç‰‡
            cover_patterns = [
                r'<img[^>]*src="([^"]*)"[^>]*video',
                r'<img[^>]*video[^>]*src="([^"]*)"',
                r'"cover":"([^"]*)"',
                r'"thumbnail":"([^"]*)"',
            ]
            
            for pattern in cover_patterns:
                match = re.search(pattern, html, re.IGNORECASE)
                if match:
                    cover_url = match.group(1)
                    if cover_url.startswith('http') or cover_url.startswith('//'):
                        if cover_url.startswith('//'):
                            cover_url = 'https:' + cover_url
                        video_info['video']['cover_url'] = cover_url
                        print(f"ğŸ–¼ï¸ æå–åˆ°å°é¢: {cover_url[:80]}...")
                        break
            
        except Exception as e:
            print(f"âš ï¸ æå–å…ƒæ•°æ®å¤±è´¥: {e}")
    
    def _try_selenium_method(self, url: str) -> Optional[Dict]:
        """ä½¿ç”¨Seleniumåœ¨DLPandaç½‘ç«™ä¸Šè·å–ä¸‹è½½é“¾æ¥"""
        try:
            print("ğŸš€ å¯åŠ¨Seleniumæµè§ˆå™¨è®¿é—®DLPanda...")
            
            # æ£€æŸ¥seleniumæ˜¯å¦å¯ç”¨
            try:
                from selenium import webdriver
                from selenium.webdriver.chrome.options import Options
                from selenium.webdriver.common.by import By
                from selenium.webdriver.support.ui import WebDriverWait
                from selenium.webdriver.support import expected_conditions as EC
                import time
            except ImportError:
                print("âŒ Seleniumä¸å¯ç”¨ï¼Œè·³è¿‡æ­¤æ–¹æ³•")
                return None
            
            # é…ç½®Chromeé€‰é¡¹
            chrome_options = Options()
            chrome_options.add_argument('--headless')  # æ— å¤´æ¨¡å¼
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            chrome_options.add_argument('--disable-gpu')
            chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
            
            # å¯åŠ¨æµè§ˆå™¨
            driver = webdriver.Chrome(options=chrome_options)
            
            try:
                print("ğŸŒ è®¿é—®DLPandaç½‘ç«™...")
                driver.get(self.base_url)
                time.sleep(2)
                
                # æ‰¾åˆ°è¾“å…¥æ¡†å¹¶è¾“å…¥URL
                print("ğŸ“ è¾“å…¥è§†é¢‘URL...")
                url_input = driver.find_element(By.ID, "url")
                url_input.clear()
                url_input.send_keys(url)
                
                # ç‚¹å‡»ä¸‹è½½æŒ‰é’®
                print("ğŸ”½ ç‚¹å‡»ä¸‹è½½æŒ‰é’®...")
                download_btn = driver.find_element(By.CSS_SELECTOR, ".one-click")
                download_btn.click()
                
                # ç­‰å¾…é¡µé¢åŠ è½½å’Œå¤„ç†
                print("â³ ç­‰å¾…å¤„ç†ç»“æœ...")
                time.sleep(10)  # ç­‰å¾…JavaScriptæ‰§è¡Œå’Œå¼‚æ­¥è¯·æ±‚
                
                # æ£€æŸ¥æ–°çš„é¡µé¢å†…å®¹
                new_html = driver.page_source
                download_links = self._extract_download_links(new_html)
                
                if download_links:
                    print(f"âœ… Seleniumæ–¹æ³•æ‰¾åˆ° {len(download_links)} ä¸ªä¸‹è½½é“¾æ¥")
                    return {
                        'html': new_html,
                        'download_links': download_links,
                        'url': driver.current_url
                    }
                else:
                    # å†ç­‰å¾…ä¸€æ®µæ—¶é—´
                    print("â³ ç»§ç»­ç­‰å¾…...")
                    time.sleep(5)
                    new_html = driver.page_source
                    download_links = self._extract_download_links(new_html)
                    
                    if download_links:
                        print(f"âœ… Seleniumæ–¹æ³•(äºŒæ¬¡æ£€æŸ¥)æ‰¾åˆ° {len(download_links)} ä¸ªä¸‹è½½é“¾æ¥")
                        return {
                            'html': new_html,
                            'download_links': download_links,
                            'url': driver.current_url
                        }
                
                print("âŒ Seleniumæ–¹æ³•æœªæ‰¾åˆ°ä¸‹è½½é“¾æ¥")
                return None
                
            finally:
                driver.quit()
                
        except Exception as e:
            print(f"âŒ Seleniumæ–¹æ³•å¤±è´¥: {e}")
            return None
    
    def is_available(self) -> bool:
        """æ£€æŸ¥DLPandaæœåŠ¡æ˜¯å¦å¯ç”¨"""
        try:
            response = requests.get(self.base_url, timeout=5)
            return response.status_code == 200
        except:
            return False
    
    def test_connection(self) -> bool:
        """æµ‹è¯•è¿æ¥"""
        try:
            print("ğŸ” æµ‹è¯•DLPandaè¿æ¥...")
            response = self.session.get(self.base_url, timeout=10)
            if response.status_code == 200:
                print("âœ… DLPandaè¿æ¥æˆåŠŸ")
                return True
            else:
                print(f"âŒ DLPandaè¿æ¥å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                return False
        except Exception as e:
            print(f"âŒ DLPandaè¿æ¥å¼‚å¸¸: {e}")
            return False